{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whK3KxX96LLk"
   },
   "source": [
    "# NLP Deep Dive with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1662025467212,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "azdWjvVbx7SM"
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 36667,
     "status": "ok",
     "timestamp": 1662025503866,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "66MuH5Pkya7Z",
    "outputId": "580c8b6e-8665-4ac1-ac37-5e3a5c50f609"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1662025503867,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "B3BNx9Y50SN7",
    "outputId": "819c3ebb-8ee8-4ef6-8260-96c7a76f2831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/jupyter/.fastai/data/imdb/test'), Path('/home/jupyter/.fastai/data/imdb/tmp_lm'), Path('/home/jupyter/.fastai/data/imdb/imdb.vocab'), Path('/home/jupyter/.fastai/data/imdb/train'), Path('/home/jupyter/.fastai/data/imdb/unsup'), Path('/home/jupyter/.fastai/data/imdb/models'), Path('/home/jupyter/.fastai/data/imdb/tmp_clas'), Path('/home/jupyter/.fastai/data/imdb/README')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 1185,
     "status": "ok",
     "timestamp": 1662025505045,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "89uRQFnk0d1E"
   },
   "outputs": [],
   "source": [
    "files = get_text_files(path, folders=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1662025505047,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "ocIXHHHn09IF",
    "outputId": "419a0bf5-e624-4074-e169-c86618fdb0ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This movie was a modern day scarface.It had me on my toes.This movie is one of those rare epic films that makes you want a sequel.I especially liked Damian Chapa his performance deserved an academy award,which he deserved for his performance in blood in blood out.The only thing I didn't like was the behind the scenes because it didn't show the intensity that the movie had,and i would have like to have seen less narrated scenes.But the movie was great and it is in my top ten movies of all time.Plus the acting was great there wasn't a bad scene in the movie,I loved it ,Jennifer Tilly was perfect as well as all of the cast.I can't see how anyone wouldn't like this movie it was a great.Definitely a must see.\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = files[0].open().read(); txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qk67zzy6T6g"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14980,
     "status": "ok",
     "timestamp": 1662025520018,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "oNd3neRa0_sS",
    "outputId": "5761277e-f0f6-4b4b-ea11-b419453faa18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.core.SpacyTokenizer object at 0x7f62f3cf8150>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy = WordTokenizer()\n",
    "spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1662025520019,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "eKRv1qcU1IoM",
    "outputId": "f694ec7f-6785-4b32-c91b-c601b10e20cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'movie', 'was', 'a', 'modern', 'day', 'scarface', '.', 'It', 'had', 'me', 'on', 'my', 'toes', '.', 'This', 'movie', 'is', 'one', 'of', 'those', 'rare', 'epic', 'films', 'that', 'makes', 'you', 'want', 'a', 'sequel', '.', 'I', 'especially', 'liked', 'Damian', 'Chapa', 'his', 'performance', 'deserved', 'an', 'academy', 'award', ',', 'which', 'he', 'deserved', 'for', 'his', 'performance', 'in', 'blood', 'in', 'blood', 'out', '.', 'The', 'only', 'thing', 'I', 'did', \"n't\", 'like', 'was', 'the', 'behind', 'the', 'scenes', 'because', 'it', 'did', \"n't\", 'show', 'the', 'intensity', 'that', 'the', 'movie', 'had', ',', 'and', 'i', 'would', 'have', 'like', 'to', 'have', 'seen', 'less', 'narrated', 'scenes', '.', 'But', 'the', 'movie', 'was', 'great', 'and', 'it', 'is', 'in', 'my', 'top', 'ten', 'movies', 'of', 'all', 'time', '.', 'Plus', 'the', 'acting', 'was', 'great', 'there', 'was', \"n't\", 'a', 'bad', 'scene', 'in', 'the', 'movie', ',', 'I', 'loved', 'it', ',', 'Jennifer', 'Tilly', 'was', 'perfect', 'as', 'well', 'as', 'all', 'of', 'the', 'cast', '.', 'I', 'ca', \"n't\", 'see', 'how', 'anyone', 'would', \"n't\", 'like', 'this', 'movie', 'it', 'was', 'a', 'great', '.', 'Definitely', 'a', 'must', 'see', '.']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy tokenizes our text with the deafult settings here, tokenizing by spaces \n",
    "toks = first(spacy([txt])); toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1662025520020,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "4dvCvDYM1VWb",
    "outputId": "da3abbad-e4dd-4865-dbd5-6e96148653e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'fastcore.foundation.L'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1662025520021,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "qUfrNnWw2KLe",
    "outputId": "d7c0d729-66d6-4036-e293-63069f680071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#160) ['This','movie','was','a','modern','day','scarface','.','It','had','me','on','my','toes','.','This','movie','is','one','of','those','rare','epic','films','that','makes','you','want','a','sequel','.','I','especially','liked','Damian','Chapa','his','performance','deserved','an','academy','award',',','which','he','deserved','for','his','performance','in'...]\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hmm is this fastai function really necessary? just gets a string representation to show more values... ü§∑‚Äç‚ôÄÔ∏è\n",
    "coll_repr(toks, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1662025520023,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "SfQgEn8V2dKj",
    "outputId": "33176eb3-75d7-4d16-9624-143c16cdd31c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#149) ['xxbos','xxmaj','this','movie','was','a','modern','day','scarface.it','had','me','on','my','toes.this','movie','is','one','of','those','rare','epic','films','that','makes','you','want','a','sequel.i','especially','liked','xxmaj','damian','xxmaj','chapa','his','performance','deserved','an','academy','award',',','which','he','deserved','for','his','performance','in','blood','in'...]\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets use fastai's tokenizer \n",
    "tkn = Tokenizer(spacy)\n",
    "coll_repr(tkn(txt), 50)\n",
    "# we see fastai's special tokens representing \"beginning of stream\", \"capital letter incoming!\" etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1662025520023,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "CiGEXJTE4BBy",
    "outputId": "723eff39-ef1f-4f1a-a15f-03d83ff995f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'hello', 'xxmaj', 'i', \"'m\", 'going', 'to', 'use', 'an', 'invalid', 'english', 'word', 'tootyfruitcake']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tkn('hello I\\'m going to use an invalid english word tootyfruitcake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1662025520024,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "wmTM-pLR4k56",
    "outputId": "ea90dfd3-d857-4183-8df8-98673fe72f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#11) ['xxbos','¬©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_repr(tkn('&copy;     Fast.ai www.fast.ai/INDEX'), 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO5vN9GT5_5a"
   },
   "source": [
    "## Subword Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1662025520814,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "Lk-G3yt56HaA"
   },
   "outputs": [],
   "source": [
    "txts = L(f.open().read() for f in files[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1662025520815,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "ZV6GjVsQ6ey0",
    "outputId": "c2d2b9bc-bfcf-4b27-d4e4-bb4291ca8c02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1662025520816,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "A-BGIixk62y6",
    "outputId": "896a22fe-218a-4b8b-f88d-9ed3d7140589"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([len(t) for t in txts]).hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece!=0.1.90,!=0.1.91 in /opt/conda/lib/python3.7/site-packages (0.1.97)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentencepiece!=0.1.90,!=0.1.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1662025520816,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "jpD41W6Y8TrP",
    "outputId": "709073dc-7974-412e-c98f-c2f9caa45212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.core.SentencePieceTokenizer object at 0x7f62f3ccb110>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SubwordTokenizer(vocab_sz=1000)\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 9016,
     "status": "ok",
     "timestamp": 1662025529818,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "8CKu3nYS7VwY",
    "outputId": "f82d78d6-4d95-4e0b-bc19-f0efb263b1e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'‚ñÅThis ‚ñÅmovie ‚ñÅwas ‚ñÅa ‚ñÅmo der n ‚ñÅday ‚ñÅsc ar f a ce . I t ‚ñÅhad ‚ñÅme ‚ñÅon ‚ñÅmy ‚ñÅto es . This ‚ñÅmovie ‚ñÅis ‚ñÅone ‚ñÅof ‚ñÅthose ‚ñÅra re ‚ñÅe p ic ‚ñÅfilms ‚ñÅthat ‚ñÅmakes ‚ñÅyou ‚ñÅwant ‚ñÅa'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.setup(txts)\n",
    "\" \".join(first(sp([txt]))[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1662025529819,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "aKg0Uk6A6hQJ"
   },
   "outputs": [],
   "source": [
    "def subword(sz):\n",
    "  \"\"\"\n",
    "  tokenizes our hardcoded text with a given subword token size \n",
    "  \"\"\"\n",
    "  sp = SubwordTokenizer(vocab_sz=sz)\n",
    "  sp.setup(txts)\n",
    "  return \" \".join(first(sp([txt]))[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 12175,
     "status": "ok",
     "timestamp": 1662025541979,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "D2GhigXv-_Zn",
    "outputId": "d90557d3-a4f1-47d6-def2-50edef0a254e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'‚ñÅ T h i s ‚ñÅmovie ‚ñÅwas ‚ñÅa ‚ñÅmo d er n ‚ñÅ d a y ‚ñÅ s c ar f a ce . I t ‚ñÅh a d ‚ñÅ m e ‚ñÅon ‚ñÅ m y ‚ñÅto es . T'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLy9KTwk_IuV"
   },
   "source": [
    "## Numericalization\n",
    "\n",
    "We need to map each token to an index so we can represent words in our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1662025542001,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "xvxQ753lALV3",
    "outputId": "1315d7a6-89f7-4bfb-fb75-f5c908ad6360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'xxmaj', 'this', 'movie', 'was', 'a', 'modern', 'day', 'scarface.it', 'had', 'me', 'on', 'my', 'toes.this', 'movie', 'is', 'one', 'of', 'those', 'rare', 'epic', 'films', 'that', 'makes', 'you', 'want', 'a', 'sequel.i', 'especially', 'liked', 'xxmaj', 'damian', 'xxmaj', 'chapa', 'his', 'performance', 'deserved', 'an', 'academy', 'award', ',', 'which', 'he', 'deserved', 'for', 'his', 'performance', 'in', 'blood', 'in', 'blood', 'out.the', 'only', 'thing', 'i', 'did', \"n't\", 'like', 'was', 'the', 'behind', 'the', 'scenes', 'because', 'it', 'did', \"n't\", 'show', 'the', 'intensity', 'that', 'the', 'movie', 'had', ',', 'and', 'i', 'would', 'have', 'like', 'to', 'have', 'seen', 'less', 'narrated', 'scenes.but', 'the', 'movie', 'was', 'great', 'and', 'it', 'is', 'in', 'my', 'top', 'ten', 'movies', 'of', 'all', 'time.plus', 'the', 'acting', 'was', 'great', 'there', 'was', \"n't\", 'a', 'bad', 'scene', 'in', 'the', 'movie', ',', 'i', 'loved', 'it', ',', 'jennifer', 'xxmaj', 'tilly', 'was', 'perfect', 'as', 'well', 'as', 'all', 'of', 'the', 'cast.i', 'ca', \"n't\", 'see', 'how', 'anyone', 'would', \"n't\", 'like', 'this', 'movie', 'it', 'was', 'a', 'great.definitely', 'a', 'must', 'see', '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkn(txts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1662025543083,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "ok6jHd8UAUul",
    "outputId": "cb410341-148d-4afe-8080-cd0806cf53e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'xxmaj', 'this', 'movie', 'was', 'a', 'modern', 'day', 'scarface.it', 'had', 'me', 'on', 'my', 'toes.this', 'movie', 'is', 'one', 'of', 'those', 'rare', 'epic', 'films', 'that', 'makes', 'you', 'want', 'a', 'sequel.i', 'especially', 'liked', 'xxmaj', 'damian', 'xxmaj', 'chapa', 'his', 'performance', 'deserved', 'an', 'academy', 'award', ',', 'which', 'he', 'deserved', 'for', 'his', 'performance', 'in', 'blood', 'in', 'blood', 'out.the', 'only', 'thing', 'i', 'did', \"n't\", 'like', 'was', 'the', 'behind', 'the', 'scenes', 'because', 'it', 'did', \"n't\", 'show', 'the', 'intensity', 'that', 'the', 'movie', 'had', ',', 'and', 'i', 'would', 'have', 'like', 'to', 'have', 'seen', 'less', 'narrated', 'scenes.but', 'the', 'movie', 'was', 'great', 'and', 'it', 'is', 'in', 'my', 'top', 'ten', 'movies', 'of', 'all', 'time.plus', 'the', 'acting', 'was', 'great', 'there', 'was', \"n't\", 'a', 'bad', 'scene', 'in', 'the', 'movie', ',', 'i', 'loved', 'it', ',', 'jennifer', 'xxmaj', 'tilly', 'was', 'perfect', 'as', 'well', 'as', 'all', 'of', 'the', 'cast.i', 'ca', \"n't\", 'see', 'how', 'anyone', 'would', \"n't\", 'like', 'this', 'movie', 'it', 'was', 'a', 'great.definitely', 'a', 'must', 'see', '.']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the first 200 documents \n",
    "toks200 = txts[:200].map(tkn)\n",
    "toks200[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[149, 463, 187, 184, 183, 281, 91, 164, 227, 513, 201, 268, 159, 197, 181, 74, 324, 372, 231, 538, 167, 1168, 771, 172, 484, 273, 336, 139, 223, 163, 254, 149, 135, 229, 303, 139, 46, 401, 290, 226, 177, 174, 233, 187, 201, 454, 226, 132, 341, 335, 359, 205, 199, 172, 196, 464, 139, 125, 509, 135, 62, 843, 243, 120, 300, 634, 332, 192, 312, 153, 707, 137, 189, 206, 156, 339, 164, 266, 289, 196, 113, 175, 185, 59, 180, 182, 155, 129, 154, 56, 259, 222, 171, 84, 814, 154, 87, 149, 88, 203, 157, 723, 69, 156, 152, 154, 306, 548, 355, 194, 179, 275, 202, 126, 287, 165, 150, 174, 188, 192, 256, 262, 195, 704, 229, 183, 101, 243, 50, 275, 281, 165, 212, 369, 313, 220, 67, 432, 187, 267, 129, 193, 57, 148, 305, 180, 401, 86, 100, 173, 129, 87, 247, 182, 203, 167, 520, 135, 184, 372, 219, 183, 312, 320, 254, 183, 143, 472, 1044, 334, 195, 483, 169, 120, 196, 216, 202, 171, 266, 255, 105, 84, 292, 139, 171, 165, 129, 528, 598, 150, 195, 201, 175, 228, 427, 188, 261, 189, 633, 159]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks200.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1662025543084,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "ELenUItfAqab",
    "outputId": "d1f0b21e-68e8-4469-a5ff-1461ee7d1806"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', 'the']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set indices for the tokens that occur in the first 200 documents\n",
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "list(num.vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1662025543086,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "Q2Ucm91-Azde",
    "outputId": "0d4f4531-5000-40dc-992e-cd1bc972720f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,   20,   27,   25,   13,  628,  203,    0,   86,   83,\n",
       "              36,   73,    0,   27,   15,   39,   14,  150,  711, 1034,  148,\n",
       "              21,  162,   33,  191,   13,    0,  265,  304,    8,    0,    8,\n",
       "               0,   35,  239,  512,   49,    0,    0,   11,   89,   34,  512,\n",
       "              28,   35,  239,   17, 1035,   17])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = toks200[0] \n",
    "nums = num(toks)[:50]; nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1662025543086,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "ixfeUqDtB0T2",
    "outputId": "e4f04a9f-816d-4794-e4cd-d555618c6080"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj this movie was a modern day xxunk had me on my xxunk movie is one of those rare epic films that makes you want a xxunk especially liked xxmaj xxunk xxmaj xxunk his performance deserved an xxunk xxunk , which he deserved for his performance in blood in'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[i] for i in nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1662025543088,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "O21RCaCKB5j9",
    "outputId": "0a051d96-d557-42dc-e909-87a4c80b309c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This movie was a modern day scarface.It had me on my toes.This movie is one of those rare epic films that makes you want a sequel.I especially liked Damian Chapa his performance deserved an academy award,which he deserved for his performance in blood in blood out.The only thing I didn't like was the behind the scenes because it didn't show the intensity that the movie had,and i would have like to have seen less narrated scenes.But the movie was great and it is in my top ten movies of all time.Plus the acting was great there wasn't a bad scene in the movie,I loved it ,Jennifer Tilly was perfect as well as all of the cast.I can't see how anyone wouldn't like this movie it was a great.Definitely a must see.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-k5b26TCKEe"
   },
   "source": [
    "## Put the numbers in a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1662025543089,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "AZaKoNaCCpnU",
    "outputId": "9429a3bf-44ab-4a6d-b395-e1981ace55a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,   20,   27,   25,   13,  628,  203,    0,   86,   83,\n",
       "              36,   73,    0,   27,   15,   39,   14,  150,  711, 1034,  148,\n",
       "              21,  162,   33,  191,   13,    0,  265,  304,    8,    0,    8,\n",
       "               0,   35,  239,  512,   49,    0,    0,   11,   89,   34,  512,\n",
       "              28,   35,  239,   17, 1035,   17, 1035,    0,   88,  192,   19,\n",
       "             110,   40,   52,   25,    9,  712,    9,  164,  127,   18,  110,\n",
       "              40,   99,    9,    0,   21,    9,   27,   86,   11,   12,   19,\n",
       "              78,   47,   52,   16,   47,  121,  713,    0,    0,    9,   27,\n",
       "              25,   63,   12,   18,   15,   17,   73,  325,  854,  105,   14,\n",
       "              46,    0,    9,  142,   25,   63,   56,   25,   40,   13,  193,\n",
       "             194,   17,    9,   27,   11,   19,  251,   18,   11, 1323,    8,\n",
       "               0,   25,  289,   24,   80,   24,   46,   14,    9,    0,  227,\n",
       "              40,   69,  103,  209,   78,   40,   52,   20,   27,   18,   25,\n",
       "              13,    0,   13,  186,   69,   10])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums200 = toks200.map(num)\n",
    "nums200[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1662025543090,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "8sW2yzdIamHK"
   },
   "outputs": [],
   "source": [
    "# language model dataloader\n",
    "# LMDataLoader??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1662025543104,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "3IZU2iZIagyC"
   },
   "outputs": [],
   "source": [
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1662025543105,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "UbLMWSOzavjb",
    "outputId": "7b485449-f313-4478-88d2-b427290aef3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 72]), torch.Size([64, 72]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = first(dl)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1662025543105,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "qIae4ojDayn-",
    "outputId": "e065d11a-0782-436f-e290-4e1bb876bdbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMTensorText([[   2,    8,   20,  ...,    0,   21,    9],\n",
       "              [   9,  721,   43,  ...,   49, 1047,   78],\n",
       "              [  13,  253,    0,  ...,    0,   37,   10],\n",
       "              ...,\n",
       "              [   8,   63,  105,  ...,  648,    9,  701],\n",
       "              [ 147,   37,   15,  ...,    8,   19,  160],\n",
       "              [  27,    8,    0,  ...,   47,   70,  437]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1662025543773,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "k8BOGEbra39i"
   },
   "outputs": [],
   "source": [
    "# LmTensorText -> TensorText -> TensorBase (fastai) -> Tensor (pytorch)\n",
    "# TensorBase??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1662025543784,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "zGiQldKccyOx",
    "outputId": "976c0ce2-f16a-4fe6-d188-c7b30e3c4ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    " %pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1662025543785,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "Utm88dhZa9aH",
    "outputId": "a809ede8-fd41-4863-9610-733a11331265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'xxmaj', 'this', 'movie', 'was', 'a', 'modern', 'day', 'xxunk', 'had', 'me', 'on', 'my', 'xxunk', 'movie', 'is', 'one', 'of', 'those', 'rare', 'epic', 'films', 'that', 'makes', 'you', 'want', 'a', 'xxunk', 'especially', 'liked', 'xxmaj', 'xxunk', 'xxmaj', 'xxunk', 'his', 'performance', 'deserved', 'an', 'xxunk', 'xxunk', ',', 'which', 'he', 'deserved', 'for', 'his', 'performance', 'in', 'blood', 'in', 'blood', 'xxunk', 'only', 'thing', 'i', 'did', \"n't\", 'like', 'was', 'the', 'behind', 'the', 'scenes', 'because', 'it', 'did', \"n't\", 'show', 'the', 'xxunk', 'that', 'the']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num.vocab[a] for a in x[0,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1662025543785,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "GuFYo6jXbpqi",
    "outputId": "33078396-13aa-4dab-db0e-28359b7ae42f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxmaj', 'this', 'movie', 'was', 'a', 'modern', 'day', 'xxunk', 'had', 'me', 'on', 'my', 'xxunk', 'movie', 'is', 'one', 'of', 'those', 'rare', 'epic', 'films', 'that', 'makes', 'you', 'want', 'a', 'xxunk', 'especially', 'liked', 'xxmaj', 'xxunk', 'xxmaj', 'xxunk', 'his', 'performance', 'deserved', 'an', 'xxunk', 'xxunk', ',', 'which', 'he', 'deserved', 'for', 'his', 'performance', 'in', 'blood', 'in', 'blood', 'xxunk', 'only', 'thing', 'i', 'did', \"n't\", 'like', 'was', 'the', 'behind', 'the', 'scenes', 'because', 'it', 'did', \"n't\", 'show', 'the', 'xxunk', 'that', 'the', 'movie']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num.vocab[a] for a in y[0,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IC_uKV7ldHPc"
   },
   "source": [
    "So the \"label\" is just the same sequence but offset by one token, i.e. containing the final \"completed\" token for the sequence. Interesting... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2S64h-JdVCK"
   },
   "source": [
    "From book RE using built-in APIs to handle numericalization and tokenization. i.e., you don't actually have to manually set up these steps, they're built into TextBLock \n",
    "\n",
    "*fastai handles tokenization and numericalization automatically when TextBlock is passed to DataBlock. All of the arguments that can be passed to Tokenize and Numericalize can also be passed to TextBlock. In the next chapter we'll discuss the easiest ways to run each of these steps separately, to ease debugging‚Äîbut you can always just debug by running them manually on a subset of your data as shown in the previous sections. And don't forget about DataBlock's handy summary method, which is very useful for debugging data issues.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1662025543795,
     "user": {
      "displayName": "Chris Marais",
      "userId": "12545716403697221618"
     },
     "user_tz": -120
    },
    "id": "8TgHVVKkUiM4"
   },
   "outputs": [],
   "source": [
    "# returns a list of file paths given the imdb base path \n",
    "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "pFf-9B69Usn-"
   },
   "outputs": [],
   "source": [
    "# data loaders: language model\n",
    "\n",
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
    "    get_items=get_imdb, \n",
    "    splitter=RandomSplitter(0.1)\n",
    ").dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0B1qXghGW1uM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj films starring child actors put themselves on the back foot from the very beginning . xxmaj while there are some exceptions , the majority of kids just ca nt act and even the ones that can normally become annoying after a few minutes . xxmaj the kids in xxmaj paperhouse have managed to capture the worst of both worlds , as they 're both very annoying and they do n't have an ounce of acting ability between them</td>\n",
       "      <td>xxmaj films starring child actors put themselves on the back foot from the very beginning . xxmaj while there are some exceptions , the majority of kids just ca nt act and even the ones that can normally become annoying after a few minutes . xxmaj the kids in xxmaj paperhouse have managed to capture the worst of both worlds , as they 're both very annoying and they do n't have an ounce of acting ability between them .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>necks , and the dwarf unfortunately stops xxmaj cabot from drinking some poisoned water . xxmaj dammit , xxmaj herve , could n't you just have let him die ? xxmaj we would all have thanked you , believe me ! \\n\\n xxmaj they get out of the desert and save a slave girl from the market . xxmaj cabot gives her a lecture about loving xxunk does this guy think he is ? xxmaj john xxmaj brown xxmaj cabot</td>\n",
       "      <td>, and the dwarf unfortunately stops xxmaj cabot from drinking some poisoned water . xxmaj dammit , xxmaj herve , could n't you just have let him die ? xxmaj we would all have thanked you , believe me ! \\n\\n xxmaj they get out of the desert and save a slave girl from the market . xxmaj cabot gives her a lecture about loving xxunk does this guy think he is ? xxmaj john xxmaj brown xxmaj cabot ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvnmvg9JZK4n"
   },
   "source": [
    "### Let's train the damn thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWD_LSTM??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0NiIAiIqatL4"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# NOTE language_model_learner automatically freezes the parameters of the pretrained model, adding new \n",
    "# parameters for any new tokens in the vocab \n",
    "\n",
    "# we illustrate this below by showing that most parameters do not have gradients enabled \n",
    "for param in learn.model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3uDUd7SUauu4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2630 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception occured in `MixedPrecision` when calling event `after_pred`:\n\tCUDA out of memory. Tried to allocate 2.29 GiB (GPU 0; 14.56 GiB total capacity; 4.56 GiB already allocated; 1.35 GiB free; 4.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11179/2558650133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    117\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    118\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# %% ../nbs/14_callback.schedule.ipynb 51\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mordered_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;31m# %% ../nbs/01_basics.ipynb 336\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastcore/basics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;31m# %% ../nbs/01_basics.ipynb 326\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'missing {event_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnorm_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCancelBatchException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBackwardException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mmodify_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCancelBatchException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBackwardException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mmodify_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/callback/fp16.py\u001b[0m in \u001b[0;36mafter_pred\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mto_float\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"Recursively map lists of int tensors in `b ` to float.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;31m# %% ../nbs/00_torch_core.ipynb 71\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"Recursively map lists of int tensors in `b ` to float.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;31m# %% ../nbs/00_torch_core.ipynb 71\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception occured in `MixedPrecision` when calling event `after_pred`:\n\tCUDA out of memory. Tried to allocate 2.29 GiB (GPU 0; 14.56 GiB total capacity; 4.56 GiB already allocated; 1.35 GiB free; 4.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5suQQBva7cX"
   },
   "outputs": [],
   "source": [
    "learn.predict(\"this movie was\", n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(\"the worst\", n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'the best - known European film early in The Thin White Line . Its early phases were reserved for exploitation pictures , theaters and an expensive film for the stage . The film was adjusted for idea by two actors who acted as inventor of'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"the best\", n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'japan = a Super Smash Family Series = = a Super Smash Pack Wii Main Series ( DS ) is a pop album which takes place in the Japanese anime series Super Smash Brothers'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"\", n_words=50, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn, looks like our model is saying things about movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('1epoch') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('1epoch') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in learn.model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(10,2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.predict(\"\", n_words=200, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('unfreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"0.module.encoder.weight\", \"0.module.encoder_dp.emb.weight\", \"0.module.rnns.0.weight_hh_l0_raw\", \"0.module.rnns.0.module.weight_ih_l0\", \"0.module.rnns.0.module.bias_ih_l0\", \"0.module.rnns.0.module.bias_hh_l0\", \"0.module.rnns.1.weight_hh_l0_raw\", \"0.module.rnns.1.module.weight_ih_l0\", \"0.module.rnns.1.module.bias_ih_l0\", \"0.module.rnns.1.module.bias_hh_l0\", \"0.module.rnns.2.weight_hh_l0_raw\", \"0.module.rnns.2.module.weight_ih_l0\", \"0.module.rnns.2.module.bias_ih_l0\", \"0.module.rnns.2.module.bias_hh_l0\", \"1.layers.0.0.weight\", \"1.layers.0.0.bias\", \"1.layers.0.0.running_mean\", \"1.layers.0.0.running_var\", \"1.layers.0.2.weight\", \"1.layers.1.0.weight\", \"1.layers.1.0.bias\", \"1.layers.1.0.running_mean\", \"1.layers.1.0.running_var\", \"1.layers.1.2.weight\". \n\tUnexpected key(s) in state_dict: \"0.encoder.weight\", \"0.encoder_dp.emb.weight\", \"0.rnns.0.weight_hh_l0_raw\", \"0.rnns.0.module.weight_ih_l0\", \"0.rnns.0.module.bias_ih_l0\", \"0.rnns.0.module.bias_hh_l0\", \"0.rnns.1.weight_hh_l0_raw\", \"0.rnns.1.module.weight_ih_l0\", \"0.rnns.1.module.bias_ih_l0\", \"0.rnns.1.module.bias_hh_l0\", \"0.rnns.2.weight_hh_l0_raw\", \"0.rnns.2.module.weight_ih_l0\", \"0.rnns.2.module.bias_ih_l0\", \"0.rnns.2.module.bias_hh_l0\", \"1.decoder.weight\", \"1.decoder.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11179/2438070976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unfreeze'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, with_opt, device, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mload_model_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mload_model_text\u001b[0;34m(file, model, opt, with_opt, device, strict)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mhasopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_raw_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"0.module.encoder.weight\", \"0.module.encoder_dp.emb.weight\", \"0.module.rnns.0.weight_hh_l0_raw\", \"0.module.rnns.0.module.weight_ih_l0\", \"0.module.rnns.0.module.bias_ih_l0\", \"0.module.rnns.0.module.bias_hh_l0\", \"0.module.rnns.1.weight_hh_l0_raw\", \"0.module.rnns.1.module.weight_ih_l0\", \"0.module.rnns.1.module.bias_ih_l0\", \"0.module.rnns.1.module.bias_hh_l0\", \"0.module.rnns.2.weight_hh_l0_raw\", \"0.module.rnns.2.module.weight_ih_l0\", \"0.module.rnns.2.module.bias_ih_l0\", \"0.module.rnns.2.module.bias_hh_l0\", \"1.layers.0.0.weight\", \"1.layers.0.0.bias\", \"1.layers.0.0.running_mean\", \"1.layers.0.0.running_var\", \"1.layers.0.2.weight\", \"1.layers.1.0.weight\", \"1.layers.1.0.bias\", \"1.layers.1.0.running_mean\", \"1.layers.1.0.running_var\", \"1.layers.1.2.weight\". \n\tUnexpected key(s) in state_dict: \"0.encoder.weight\", \"0.encoder_dp.emb.weight\", \"0.rnns.0.weight_hh_l0_raw\", \"0.rnns.0.module.weight_ih_l0\", \"0.rnns.0.module.bias_ih_l0\", \"0.rnns.0.module.bias_hh_l0\", \"0.rnns.1.weight_hh_l0_raw\", \"0.rnns.1.module.weight_ih_l0\", \"0.rnns.1.module.bias_ih_l0\", \"0.rnns.1.module.bias_hh_l0\", \"0.rnns.2.weight_hh_l0_raw\", \"0.rnns.2.module.weight_ih_l0\", \"0.rnns.2.module.bias_ih_l0\", \"0.rnns.2.module.bias_hh_l0\", \"1.decoder.weight\", \"1.decoder.bias\". "
     ]
    }
   ],
   "source": [
    "learn = learn.load('unfreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"i hated this movie because i like Doris Day and did n't want to watch her and i do n't understand why people love her . i think she was worse than Doris Day . She really had a few good scenes playing Ruth Etting . She was a good actress . The music was great , the story was pretty good . In this film , Doris played a successful woman with some financial problems but she ended up being a better woman . It was so interesting to see Ruth\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I hated this movie because\", n_words=100, temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mparent_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mparent_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Label `item` with the parent folder name.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/fastai/data/transforms.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent_label??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#100002) [Path('/home/jupyter/.fastai/data/imdb/test/pos/11897_10.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/2859_8.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/7828_10.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/9293_10.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/4344_10.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/7356_8.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/12451_10.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/9120_9.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/11565_7.txt'),Path('/home/jupyter/.fastai/data/imdb/test/pos/4459_9.txt')...]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas = DataBlock(\n",
    "    blocks=(TextBlock.from_folder(path, vocab=dls_lm.vocab), CategoryBlock), \n",
    "    get_y=parent_label, \n",
    "    get_items=partial(get_text_files, folders=['train','test']),\n",
    "    splitter=GrandparentSplitter(valid_name='test')\n",
    ").dataloaders(path,path=path,bs=128,seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos * * attention xxmaj spoilers * * \\n\\n xxmaj first of all , let me say that xxmaj rob xxmaj roy is one of the best films of the 90 's . xxmaj it was an amazing achievement for all those involved , especially the acting of xxmaj liam xxmaj neeson , xxmaj jessica xxmaj lange , xxmaj john xxmaj hurt , xxmaj brian xxmaj cox , and xxmaj tim xxmaj roth . xxmaj michael xxmaj canton xxmaj jones painted a wonderful portrait of the honor and dishonor that men can represent in themselves . xxmaj but alas ‚Ä¶ \\n\\n it constantly , and unfairly gets compared to \" braveheart \" . xxmaj these are two entirely different films , probably only similar in the fact that they are both about xxmaj scots in historical xxmaj scotland . xxmaj yet , this comparison frequently bothers me because it seems</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj by now you 've probably heard a bit about the new xxmaj disney dub of xxmaj miyazaki 's classic film , xxmaj laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky . xxmaj during late summer of 1998 , xxmaj disney released \" kiki 's xxmaj delivery xxmaj service \" on video which included a preview of the xxmaj laputa dub saying it was due out in \" 1 xxrep 3 9 \" . xxmaj it 's obviously way past that year now , but the dub has been finally completed . xxmaj and it 's not \" laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky \" , just \" castle xxmaj in xxmaj the xxmaj sky \" for the dub , since xxmaj laputa is not such a nice word in xxmaj spanish ( even though they use the word xxmaj laputa many times</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_clas.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reminder: toks200 is the first 200 documents in tokenized form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_samp = toks200[:10].map(num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [149,463,187,184,183,281,91,164,227,513]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums_samp.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document has a different length, which is a problem. We solve this by grouping similarly sized input together in a batch and padding the shorter documents with a special padding token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"0.module.encoder.weight\", \"0.module.encoder_dp.emb.weight\", \"0.module.rnns.0.weight_hh_l0_raw\", \"0.module.rnns.0.module.weight_ih_l0\", \"0.module.rnns.0.module.bias_ih_l0\", \"0.module.rnns.0.module.bias_hh_l0\", \"0.module.rnns.1.weight_hh_l0_raw\", \"0.module.rnns.1.module.weight_ih_l0\", \"0.module.rnns.1.module.bias_ih_l0\", \"0.module.rnns.1.module.bias_hh_l0\", \"0.module.rnns.2.weight_hh_l0_raw\", \"0.module.rnns.2.module.weight_ih_l0\", \"0.module.rnns.2.module.bias_ih_l0\", \"0.module.rnns.2.module.bias_hh_l0\", \"1.layers.0.0.weight\", \"1.layers.0.0.bias\", \"1.layers.0.0.running_mean\", \"1.layers.0.0.running_var\", \"1.layers.0.2.weight\", \"1.layers.1.0.weight\", \"1.layers.1.0.bias\", \"1.layers.1.0.running_mean\", \"1.layers.1.0.running_var\", \"1.layers.1.2.weight\". \n\tUnexpected key(s) in state_dict: \"0.encoder.weight\", \"0.encoder_dp.emb.weight\", \"0.rnns.0.weight_hh_l0_raw\", \"0.rnns.0.module.weight_ih_l0\", \"0.rnns.0.module.bias_ih_l0\", \"0.rnns.0.module.bias_hh_l0\", \"0.rnns.1.weight_hh_l0_raw\", \"0.rnns.1.module.weight_ih_l0\", \"0.rnns.1.module.bias_ih_l0\", \"0.rnns.1.module.bias_hh_l0\", \"0.rnns.2.weight_hh_l0_raw\", \"0.rnns.2.module.weight_ih_l0\", \"0.rnns.2.module.bias_ih_l0\", \"0.rnns.2.module.bias_hh_l0\", \"1.decoder.weight\", \"1.decoder.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11179/2438070976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unfreeze'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, with_opt, device, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mload_model_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mload_model_text\u001b[0;34m(file, model, opt, with_opt, device, strict)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mhasopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_raw_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'opt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"0.module.encoder.weight\", \"0.module.encoder_dp.emb.weight\", \"0.module.rnns.0.weight_hh_l0_raw\", \"0.module.rnns.0.module.weight_ih_l0\", \"0.module.rnns.0.module.bias_ih_l0\", \"0.module.rnns.0.module.bias_hh_l0\", \"0.module.rnns.1.weight_hh_l0_raw\", \"0.module.rnns.1.module.weight_ih_l0\", \"0.module.rnns.1.module.bias_ih_l0\", \"0.module.rnns.1.module.bias_hh_l0\", \"0.module.rnns.2.weight_hh_l0_raw\", \"0.module.rnns.2.module.weight_ih_l0\", \"0.module.rnns.2.module.bias_ih_l0\", \"0.module.rnns.2.module.bias_hh_l0\", \"1.layers.0.0.weight\", \"1.layers.0.0.bias\", \"1.layers.0.0.running_mean\", \"1.layers.0.0.running_var\", \"1.layers.0.2.weight\", \"1.layers.1.0.weight\", \"1.layers.1.0.bias\", \"1.layers.1.0.running_mean\", \"1.layers.1.0.running_var\", \"1.layers.1.2.weight\". \n\tUnexpected key(s) in state_dict: \"0.encoder.weight\", \"0.encoder_dp.emb.weight\", \"0.rnns.0.weight_hh_l0_raw\", \"0.rnns.0.module.weight_ih_l0\", \"0.rnns.0.module.bias_ih_l0\", \"0.rnns.0.module.bias_hh_l0\", \"0.rnns.1.weight_hh_l0_raw\", \"0.rnns.1.module.weight_ih_l0\", \"0.rnns.1.module.bias_ih_l0\", \"0.rnns.1.module.bias_hh_l0\", \"0.rnns.2.weight_hh_l0_raw\", \"0.rnns.2.module.weight_ih_l0\", \"0.rnns.2.module.bias_ih_l0\", \"0.rnns.2.module.bias_hh_l0\", \"1.decoder.weight\", \"1.decoder.bias\". "
     ]
    }
   ],
   "source": [
    "learn = learn.load('unfreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas.vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "",
   "provenance": [
    {
     "file_id": "https://github.com/Mchristos/fastbook/blob/my-work/10_nlp_chris.ipynb",
     "timestamp": 1661947471744
    }
   ],
   "version": ""
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m95"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
